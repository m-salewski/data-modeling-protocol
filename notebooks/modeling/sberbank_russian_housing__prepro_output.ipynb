{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "repo_path = os.path.abspath(\"../../\")\n",
    "\n",
    "from git import Repo\n",
    "repo = Repo(repo_path)\n",
    "branch = repo.active_branch\n",
    "\n",
    "# Put into a convenience function to keep track of for later use\n",
    "gitb = lambda : [print(\"Current branch:\",r.active_branch.name) for r in [Repo(repo_path)]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "    Sberbank Russian Housing Market\n",
    "</font>\n",
    "\n",
    "<hr style=\"border: solid rgb(0,0,0) 0.0px; background-color: rgb(0,0,0);height: 2.0px;\"/>\n",
    "<font color='red' size=5>\n",
    "    The show so far ... \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "1. Load data\n",
    "2. Remove features\n",
    "    * features missing more than 10%\n",
    "    * features with high correlations to the other features\n",
    "        * used hierarchical correlation dropper\n",
    "3. Stage 1 transformations:\n",
    "    * Ignored features: \n",
    "        * e.g. 'id' and 'datetime' columns\n",
    "    * Scale num. features\n",
    "        * perhaps better to wait until after \n",
    "            1. cat. encoding is done with ordinals\n",
    "            2. imputation for (all) features\n",
    "    * Cat. features\n",
    "        * used Ordinal and OneHot-encoders\n",
    "        * used custom encoder to include NANs\n",
    "    * Retrieve column names        \n",
    "    * Recast all features as needed\n",
    "4. Stage 2 transformations:\n",
    "    * Ignored features: \n",
    "        * e.g. 'id' and 'datetime' columns\n",
    "    * Impute remaining features\n",
    "        * Used `SimpleImputer`\n",
    "        * `KNNImputer` failed\n",
    "    * Retrieve column names\n",
    "    * Recast all features as needed\n",
    "\n",
    "5. Modeling\n",
    "\n",
    "6. Evaluate errors\n",
    "\n",
    "7. Feature importance\n",
    "\n",
    "**TODOs**\n",
    "\n",
    "0. Priorities\n",
    "   1. $\\checkmark$ ~~Remove the target feature for the pipeline?~~\n",
    "        * if the pipeline is fit for the independent features, then it should work with them alone;\n",
    "        * whatever preprocessing is needed for the target feature can be done independently, outside of the pipeline \n",
    "   \n",
    "1. $\\checkmark$ ~~Get the columns names of the transformed data after the `Pipeline` / `ColumnTransformer` steps~~\n",
    "    * _Needed for checking, further exploration, and featuring engineering_\n",
    "    \n",
    "2. Check on the appropriate strategies\n",
    "    * $\\checkmark$ ~~first do cat. encoding with `ColumnTransformer`, then do scaling on numericals in another `Pipeline`~~\n",
    "    * ~~do everything in a single `Pipeline` taking care of the steps~~ $\\to$ everything done with `ColumnTransformer` instead\n",
    "        * allows individual selection of features for transformations\n",
    "    * ~~Drop features with many unfilled values (can't do _after_ imputing) or just impute?, then pipeline~~ \n",
    "        * $\\checkmark$ ~~Drop features with many unfilled values before/after preprocessing?~~\n",
    "        * $\\checkmark$ ~~impute afterwards~~\n",
    "\n",
    "3. $\\checkmark$ ~~Drop features which are mutually correlated; keep only the most relevant ones~~\n",
    "    * **!!!** do this before first preprocessing stage?\n",
    "\n",
    "4. More EDA\n",
    "    * Identify quantities to be removed:\n",
    "        * $\\checkmark$ ~~IDs which contribute to the spikes in the neg. tail of the 'price_doc' distribution~~ $\\to$ _this led to a big step in improvement_\n",
    "            * ~~or see if they're correlated with another feature, like 'sub_area'~~ $\\to$ did not find this; just removed sampled IDs\n",
    "            * **open** \n",
    "                * is it possible to automatically detect narrow-bin spikes in a distribution? and eleminate the rows which contribute to them?\n",
    "        * $\\checkmark$ ~~check the distribution of the 'sub_area' feature~~\n",
    "            * ~~are there enough samples for each category?~~ \n",
    "\n",
    "5. More feature engineering\n",
    "    * There are a few more things which can be done to see if there's an improvement:\n",
    "        * $\\checkmark$ ~~removing some IDs (rows) which have some outlier behavior (clearly defined spikes in distributions)~~\n",
    "        * aggregating some features together (e.g. combining nearby 'sub_areas') $\\to$ needs some ad hoc investigations\n",
    "        * $\\checkmark$ Using the classifiers to identify and reduce the number of features to only the important ones. $\\to$ _no improvement; slightly worse with XGB_\n",
    "            * $\\checkmark$ removed the 'sub_area' feature entirely $\\to$ _no improvement_\n",
    "            * **TODO** try with other classifiers\n",
    "\n",
    "6. Try to package up the routine into a single stage with a multistep pipeline\n",
    "    * The issue is employing the KNN_imputer\n",
    "        * the issue _was_ keeping track of the columns since the stages work on different subsets;\n",
    "    * An idea would be to\n",
    "        1. Order the columns first by datatype\n",
    "        2. Then do the structure-preserving transformations (transformations which preserve the number of columns) like scaling, ordinal encoding, imputing(?))\n",
    "        3. Then do the transformations like OneHotEnc \n",
    "    * **Notes**\n",
    "        * since ther original plan was to use the KNN-imputer, where all features were needed together, this meant\n",
    "            1. process the num. and cat. features separately\n",
    "            2. re-attach columns and re-cast dtypes\n",
    "            3. apply the KNN-imputer\n",
    "    * **IDEA** to generalize, need a flexible pipeline \n",
    "        * `overall_pipeline([sub_pipeline1(data_subsetA, data_subsetB, data_subsetC), sub_pipeline2(data_subsetA, data_subset_rest),...])`\n",
    "        * the problem is keeping track of the columns since after the first subpipeline, they will be lost.\n",
    "            \n",
    "**Notes**\n",
    "* All transforms were included with `ColumnTransformer`\n",
    "    * selects cols individually\n",
    "    * can act as a pipeline\n",
    "    * retrieve the columns names and ordering\n",
    "        * _this is important to do the next steps of processing_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: solid rgb(0,0,0) 0.0px; background-color: rgb(0,0,0);height: 2.0px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# This will reload imports before executing code, allowing you to easily change contents of custom scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, 20)]\n",
    "random.shuffle(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "import sys\n",
    "sys.path.append('./helpers/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/sberbank-russian-housing-market/train.csv', \\\n",
    "                 infer_datetime_format=True, parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30471, 292)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dtypes of the DF; save to a dict for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtypes = df.dtypes.reset_index().rename(columns={'index':'column', 0:'datatype'})\n",
    "df_dtype_dict = dict(zip(df_dtypes.column, df_dtypes.datatype.astype(str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature work: the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** the target feature may also need to be transformed, _e.g._ rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'price_doc'\n",
    "target_col = [target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16331452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_doc\n",
       "0    5850000\n",
       "1    6000000\n",
       "2    5700000\n",
       "3   13100000\n",
       "4   16331452"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targ = df[['id']+target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=target_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importance_dropped_cols = ['incineration_raion', 'big_market_raion', 'sub_area']\n",
    "#df = df.drop(columns=feature_importance_dropped_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect and clean the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.047100e+04\n",
       "mean     7.123035e+06\n",
       "std      4.780111e+06\n",
       "min      1.000000e+05\n",
       "25%      4.740002e+06\n",
       "50%      6.274411e+06\n",
       "75%      8.300000e+06\n",
       "max      1.111111e+08\n",
       "Name: price_doc, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ['price_doc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_vals = df_targ['price_doc'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter the smoothed IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally, these should all be chosen from inspection; this was done already in \n",
    "# * sberbank_russian_housing__dropping_rows_via_distribution_outliers_exploration.ipynb\n",
    "# * \n",
    "bin_width = 1e5\n",
    "bins=np.arange(bin_width, 1.2e8 + bin_width, bin_width)\n",
    "peaks = np.arange(1,20.5,0.5)*1e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribution_tools import get_smooth_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id_list = get_smooth_ids(df_targ, 'id', 'price_doc', peaks, bin_width, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(map(int, id_list))\n",
    "df_targ = df_targ[df_targ['id'].isin(id_list)].copy()\n",
    "df = df[df['id'].isin(id_list)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature work: the rest\n",
    "\n",
    "#### Separate some features based on type and/or use\n",
    "\n",
    "##### Identify the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['id','timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.drop(columns=ignore_cols).select_dtypes('float').columns.tolist()\n",
    "\n",
    "int_cols = df.drop(columns=ignore_cols).select_dtypes('int').columns.tolist()\n",
    "\n",
    "num_cols = df.drop(columns=ignore_cols).select_dtypes(['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "string_cols = df.drop(columns=ignore_cols).select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop features\n",
    "\n",
    "#### Characterize the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.fill_rates import get_column_fill_rates, get_row_fill_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fillrates = get_column_fill_rates(df,0.0)\n",
    "unfilled_cols = df_fillrates[df_fillrates['frac_full']<=0.90]['column_name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the fill rate of the features\n",
    "\n",
    "Keep all features having more than 90% (arbitrary) of their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>frac_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>cafe_sum_2000_min_price_avg</td>\n",
       "      <td>0.939471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>cafe_sum_2000_max_price_avg</td>\n",
       "      <td>0.939471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>cafe_avg_price_2000</td>\n",
       "      <td>0.939471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>cafe_sum_3000_min_price_avg</td>\n",
       "      <td>0.965377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>cafe_avg_price_3000</td>\n",
       "      <td>0.965377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>cafe_sum_3000_max_price_avg</td>\n",
       "      <td>0.965377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>cafe_sum_5000_min_price_avg</td>\n",
       "      <td>0.989865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>cafe_sum_5000_max_price_avg</td>\n",
       "      <td>0.989865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>cafe_avg_price_5000</td>\n",
       "      <td>0.989865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>prom_part_5000</td>\n",
       "      <td>0.993763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column_name  frac_full\n",
       "229  cafe_sum_2000_min_price_avg   0.939471\n",
       "230  cafe_sum_2000_max_price_avg   0.939471\n",
       "231          cafe_avg_price_2000   0.939471\n",
       "252  cafe_sum_3000_min_price_avg   0.965377\n",
       "254          cafe_avg_price_3000   0.965377\n",
       "253  cafe_sum_3000_max_price_avg   0.965377\n",
       "275  cafe_sum_5000_min_price_avg   0.989865\n",
       "276  cafe_sum_5000_max_price_avg   0.989865\n",
       "277          cafe_avg_price_5000   0.989865\n",
       "269               prom_part_5000   0.993763"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.90\n",
    "df_fillrates = get_column_fill_rates(df,threshold)\n",
    "display(df_fillrates.sort_values(\"frac_full\", ascending=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features more than 90% filled: 256\n"
     ]
    }
   ],
   "source": [
    "filled_cols = df_fillrates.column_name.tolist()\n",
    "print(f'Number of features more than {round(100*threshold)}% filled: { len(filled_cols)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the fill rate of the rows\n",
    "\n",
    "**Note** this is passive; nothing is done with this info; it will also change when the unfilled features are removed\n",
    "\n",
    "<font color='red' size=2>\n",
    "    If this were applied, then the target_feature would need to be included (or matched by keeping the `id`)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>row_counts</th>\n",
       "      <th>frac_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>9098</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>28430</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>3624</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>3670</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8078</th>\n",
       "      <td>8710</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>7172</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>3773</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8427</th>\n",
       "      <td>9083</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26186</th>\n",
       "      <td>28311</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27202</th>\n",
       "      <td>29388</td>\n",
       "      <td>250</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  row_counts  frac_full\n",
       "8441    9098         250   0.859107\n",
       "26297  28430         250   0.859107\n",
       "3235    3624         250   0.859107\n",
       "3281    3670         250   0.859107\n",
       "8078    8710         250   0.859107\n",
       "6611    7172         250   0.859107\n",
       "3380    3773         250   0.859107\n",
       "8427    9083         250   0.859107\n",
       "26186  28311         250   0.859107\n",
       "27202  29388         250   0.859107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.85\n",
    "df_fillrates = get_row_fill_rates(df,threshold)\n",
    "display(df_fillrates.sort_values(\"frac_full\", ascending=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features more than 85% filled: 28217\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of features more than {round(100*threshold)}% filled: { df_fillrates.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the information content of the features\n",
    "\n",
    "If the features contain little useful information (_ie_ they have low variance), they might not contribute much to the model. \n",
    "<br/>\n",
    "For efficiecy reasons, it might be best to drop these, though the resulting model will likely be unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oil_chemistry_raion: 99.04316%\n",
      "no     27948\n",
      "yes      270\n",
      "Name: oil_chemistry_raion, dtype: int64\n",
      "\n",
      "railroad_terminal_raion: 96.22936%\n",
      "no     27154\n",
      "yes     1064\n",
      "Name: railroad_terminal_raion, dtype: int64\n",
      "\n",
      "nuclear_reactor_raion: 97.32086%\n",
      "no     27462\n",
      "yes      756\n",
      "Name: nuclear_reactor_raion, dtype: int64\n",
      "\n",
      "big_road1_1line: 97.46261%\n",
      "no     27502\n",
      "yes      716\n",
      "Name: big_road1_1line, dtype: int64\n",
      "\n",
      "railroad_1line: 97.04444%\n",
      "no     27384\n",
      "yes      834\n",
      "Name: railroad_1line, dtype: int64\n",
      "\n",
      "cafe_count_500_price_high: 97.18974%\n",
      "0    27425\n",
      "1      754\n",
      "2       31\n",
      "3        8\n",
      "Name: cafe_count_500_price_high, dtype: int64\n",
      "\n",
      "mosque_count_500: 99.53930%\n",
      "0    28088\n",
      "1      130\n",
      "Name: mosque_count_500, dtype: int64\n",
      "\n",
      "leisure_count_500: 95.07052%\n",
      "0    26827\n",
      "1     1154\n",
      "2      119\n",
      "4       48\n",
      "3       44\n",
      "9        8\n",
      "5        7\n",
      "7        6\n",
      "6        4\n",
      "8        1\n",
      "Name: leisure_count_500, dtype: int64\n",
      "\n",
      "cafe_count_1000_price_high: 95.56312%\n",
      "0    26966\n",
      "1     1027\n",
      "2      130\n",
      "3       42\n",
      "4       33\n",
      "5       11\n",
      "6        8\n",
      "7        1\n",
      "Name: cafe_count_1000_price_high, dtype: int64\n",
      "\n",
      "mosque_count_1000: 98.15720%\n",
      "0    27698\n",
      "1      520\n",
      "Name: mosque_count_1000, dtype: int64\n",
      "\n",
      "mosque_count_1500: 96.37465%\n",
      "0    27195\n",
      "1     1023\n",
      "Name: mosque_count_1500, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(df.index)\n",
    "low_information_cols = [] #\n",
    "\n",
    "for col in df.columns:\n",
    "    cnts = df[col].value_counts(dropna=False)\n",
    "    top_pct = (cnts/num_rows).iloc[0]\n",
    "    \n",
    "    if top_pct > 0.95:\n",
    "        low_information_cols.append(col)\n",
    "        print('{0}: {1:.5f}%'.format(col, top_pct*100))\n",
    "        print(cnts)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_information_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping rows of cat. features with low representation\n",
    "\n",
    "Consider dropping rows which contribute to the tail-end of features' distributions\n",
    "\n",
    "(_Ideally, they would be outliers in several features, but this is difficult to check with no promise of a significant reward_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_area: 6.26905%\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(df.index)\n",
    "low_rep_cat_cols = [] #\n",
    "\n",
    "col = 'sub_area'\n",
    "cnts = df[col].value_counts(dropna=False)\n",
    "top_pct = (cnts/num_rows).iloc[0]\n",
    "\n",
    "low_rep_cat_cols.append(col)\n",
    "print('{0}: {1:.5f}%'.format(col, top_pct*100))\n",
    "df_cnts = cnts.reset_index().rename(columns={'index':'sub_area', 'sub_area':'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnts['%'] = df_cnts.counts.apply(lambda x: round(100.*x/num_rows,2))\n",
    "df_cnts = df_cnts.sort_values('counts',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_area</th>\n",
       "      <th>counts</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poselenie Sosenskoe</td>\n",
       "      <td>1769</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nekrasovka</td>\n",
       "      <td>1600</td>\n",
       "      <td>5.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poselenie Vnukovskoe</td>\n",
       "      <td>1372</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poselenie Moskovskij</td>\n",
       "      <td>922</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poselenie Voskresenskoe</td>\n",
       "      <td>712</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tverskoe</td>\n",
       "      <td>662</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mitino</td>\n",
       "      <td>654</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Poselenie Filimonkovskoe</td>\n",
       "      <td>496</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Krjukovo</td>\n",
       "      <td>491</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mar'ino</td>\n",
       "      <td>469</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Poselenie Shherbinka</td>\n",
       "      <td>435</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Juzhnoe Butovo</td>\n",
       "      <td>406</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zapadnoe Degunino</td>\n",
       "      <td>394</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Solncevo</td>\n",
       "      <td>384</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Poselenie Desjonovskoe</td>\n",
       "      <td>361</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Otradnoe</td>\n",
       "      <td>324</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nagatinskij Zaton</td>\n",
       "      <td>311</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nagornoe</td>\n",
       "      <td>291</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Izmajlovo</td>\n",
       "      <td>283</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bogorodskoe</td>\n",
       "      <td>279</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sub_area  counts     %\n",
       "0        Poselenie Sosenskoe    1769  6.27\n",
       "1                 Nekrasovka    1600  5.67\n",
       "2       Poselenie Vnukovskoe    1372  4.86\n",
       "3       Poselenie Moskovskij     922  3.27\n",
       "4    Poselenie Voskresenskoe     712  2.52\n",
       "5                   Tverskoe     662  2.35\n",
       "6                     Mitino     654  2.32\n",
       "7   Poselenie Filimonkovskoe     496  1.76\n",
       "8                   Krjukovo     491  1.74\n",
       "9                    Mar'ino     469  1.66\n",
       "10      Poselenie Shherbinka     435  1.54\n",
       "11            Juzhnoe Butovo     406  1.44\n",
       "12         Zapadnoe Degunino     394  1.40\n",
       "13                  Solncevo     384  1.36\n",
       "14    Poselenie Desjonovskoe     361  1.28\n",
       "15                  Otradnoe     324  1.15\n",
       "16         Nagatinskij Zaton     311  1.10\n",
       "17                  Nagornoe     291  1.03\n",
       "18                 Izmajlovo     283  1.00\n",
       "19               Bogorodskoe     279  0.99"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 0.011163087391027005\n"
     ]
    }
   ],
   "source": [
    "cats_to_exclude = []\n",
    "counts = 0\n",
    "for n,r in df_cnts.sort_values('counts').iterrows():\n",
    "\n",
    "    if counts/num_rows > 0.01:\n",
    "        print(counts, counts/num_rows)\n",
    "        break\n",
    "    counts += r['counts']\n",
    "    cats_to_exclude.append(r['sub_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "['Poselenie Mihajlovo-Jarcevskoe', 'Poselenie Shhapovskoe', 'Poselenie Kievskij', 'Molzhaninovskoe', 'Poselenie Marushkinskoe', 'Vostochnoe', 'Poselenie Voronovskoe', 'Arbat', 'Poselenie Kokoshkino', 'Poselenie Mosrentgen', 'Poselenie Krasnopahorskoe', \"Krasnosel'skoe\", 'Severnoe', 'Poselenie Rogovskoe', 'Poselenie Rjazanovskoe', 'Vnukovo', \"Zamoskvorech'e\"]\n"
     ]
    }
   ],
   "source": [
    "print(len(cats_to_exclude))\n",
    "print(cats_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_area</th>\n",
       "      <th>counts</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Zamoskvorech'e</td>\n",
       "      <td>47</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Vnukovo</td>\n",
       "      <td>43</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Poselenie Rjazanovskoe</td>\n",
       "      <td>34</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Poselenie Rogovskoe</td>\n",
       "      <td>31</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Severnoe</td>\n",
       "      <td>31</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Krasnosel'skoe</td>\n",
       "      <td>30</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Poselenie Krasnopahorskoe</td>\n",
       "      <td>25</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Poselenie Mosrentgen</td>\n",
       "      <td>17</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Poselenie Kokoshkino</td>\n",
       "      <td>17</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Arbat</td>\n",
       "      <td>14</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Poselenie Voronovskoe</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Vostochnoe</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Poselenie Marushkinskoe</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Molzhaninovskoe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Poselenie Kievskij</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Poselenie Shhapovskoe</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Poselenie Mihajlovo-Jarcevskoe</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           sub_area  counts     %\n",
       "128                  Zamoskvorech'e      47  0.17\n",
       "129                         Vnukovo      43  0.15\n",
       "130          Poselenie Rjazanovskoe      34  0.12\n",
       "131             Poselenie Rogovskoe      31  0.11\n",
       "132                        Severnoe      31  0.11\n",
       "133                  Krasnosel'skoe      30  0.11\n",
       "134       Poselenie Krasnopahorskoe      25  0.09\n",
       "136            Poselenie Mosrentgen      17  0.06\n",
       "135            Poselenie Kokoshkino      17  0.06\n",
       "137                           Arbat      14  0.05\n",
       "138           Poselenie Voronovskoe       7  0.02\n",
       "139                      Vostochnoe       7  0.02\n",
       "140         Poselenie Marushkinskoe       5  0.02\n",
       "141                 Molzhaninovskoe       3  0.01\n",
       "142              Poselenie Kievskij       2  0.01\n",
       "143           Poselenie Shhapovskoe       1  0.00\n",
       "144  Poselenie Mihajlovo-Jarcevskoe       1  0.00"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnts[df_cnts['sub_area'].isin(cats_to_exclude)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes** \n",
    "\n",
    "Strategies:\n",
    "* drop the rows with these values $\\to$ _means no prediction will be made for these!!!_\n",
    "* combine these values into a new value, e.g. `'other'`\n",
    "* (advanced) combine nearby regions of low counts into neighbors with higher counts\n",
    "\n",
    "<font color='red' size=3>\n",
    "    Warning: as above, if this were applied, then the target_feature would need to be included (or matched by keeping the `id`)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation-based feature drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.correlation_feature_drop import get_dropped_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: be sure to include the target feature in the correlation --> the current function requires it.\n",
    "df_corr = df.drop(columns=ignore_cols+string_cols)\n",
    "df_corr[target_feature] = df_targ['price_doc']\n",
    "df_corr = df_corr.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col1', 'col2', 'corr'], dtype='object')\n",
      "Index(['col1', 'col2', 'corr', 'self', 'price_doc'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "drop_corr_cols = get_dropped_columns(df_corr, target_feature, threshold, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the cols to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [c for c in df.columns.tolist() if (c in filled_cols) & (c not in drop_corr_cols + low_information_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28218, 102)\n",
      "(28218, 102)\n"
     ]
    }
   ],
   "source": [
    "df = df[keep_cols]\n",
    "print(df.shape) #(30471, 116)\n",
    "#df = df[df['sub_area'].isin(cats_to_exclude)==False].copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the categorical then do encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** need to regrab the new set of string cols since some were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = df.drop(columns=ignore_cols).select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product_type', 'sub_area', 'culture_objects_top_25', 'thermal_power_plant_raion', 'incineration_raion', 'radiation_raion', 'big_market_raion', 'detention_facility_raion', 'water_1line', 'ecology']\n"
     ]
    }
   ],
   "source": [
    "print(string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>culture_objects_top_25</th>\n",
       "      <th>thermal_power_plant_raion</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>radiation_raion</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>water_1line</th>\n",
       "      <th>ecology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Bibirevo</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Nagatinskij Zaton</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Tekstil'shhiki</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Mitino</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Basmannoe</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type           sub_area culture_objects_top_25  \\\n",
       "0   Investment           Bibirevo                     no   \n",
       "1   Investment  Nagatinskij Zaton                    yes   \n",
       "2   Investment     Tekstil'shhiki                     no   \n",
       "3   Investment             Mitino                     no   \n",
       "4   Investment          Basmannoe                     no   \n",
       "\n",
       "  thermal_power_plant_raion incineration_raion radiation_raion  \\\n",
       "0                        no                 no              no   \n",
       "1                        no                 no              no   \n",
       "2                        no                 no             yes   \n",
       "3                        no                 no              no   \n",
       "4                        no                 no             yes   \n",
       "\n",
       "  big_market_raion detention_facility_raion water_1line    ecology  \n",
       "0               no                       no          no       good  \n",
       "1               no                       no          no  excellent  \n",
       "2               no                       no          no       poor  \n",
       "3               no                       no          no       good  \n",
       "4               no                       no          no  excellent  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[string_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "* Ordinals:\n",
    "    * 'ecology'\n",
    "* OneHots\n",
    "    * 'sub_area', 'product_type' (but only two vals)\n",
    "* Binaries\n",
    "    * the rest\n",
    "    * _But these will also be considered ordinals_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~<font color='red' size=3>\n",
    "    EDIT: dropped 'sub_area' functionality\n",
    "</font>~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import categorical_encoding\n",
    "from categorical_encoding import OrdinalEncoderNans\n",
    "\n",
    "\n",
    "onehot_cat_cols = [\"sub_area\", \"product_type\"]\n",
    "#onehot_cat_cols = [\"product_type\"]\n",
    "\n",
    "ord4_cat_cols = [\"ecology\"]\n",
    "ord4_cats = ['poor', 'satisfactory', 'good', 'excellent', 'no data'] # Normally, this is a nested list, ie [[1,2,3,...]]\n",
    "\n",
    "ord2_cat_cols = [e for e in string_cols if (e not in onehot_cat_cols) & (e not in ord4_cat_cols) ]\n",
    "ord2_cats = len(ord2_cat_cols)*[[\"no\", \"yes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_area        145\n",
       "product_type      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[onehot_cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 2 7 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_sum = sum(df[onehot_cat_cols].nunique())\n",
    "\n",
    "print(len(num_cols), len(onehot_cat_cols), len(ord2_cat_cols), len(ord4_cat_cols))\n",
    "sum([len(num_cols), onehot_sum, len(ord2_cat_cols), len(ord4_cat_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines\n",
    "\n",
    "##### Numerical features in a pipeline\n",
    "\n",
    "**Note** could also use with the ColumnTransformer, like the cat. features, since is only one transform on the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "# Use in ColumnTransformer as \n",
    "#   (\"num_pipe\",  num_pipeline, num_cols),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### putting the cat-encs together into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to re-grab the numerics as well!\n",
    "num_cols = df.drop(columns=ignore_cols).select_dtypes(['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline_stage1 = ColumnTransformer([    \n",
    "        (\"ignored\",   FunctionTransformer(lambda x: x), ignore_cols),\n",
    "        #(\"target\",  StandardScaler(), target_col),  \n",
    "        (\"num_cols\",  StandardScaler(), num_cols),  \n",
    "        (\"onehots\",   OneHotEncoder(sparse=False), onehot_cat_cols),\n",
    "        (\"ordinals2\", OrdinalEncoder(ord2_cats), ord2_cat_cols),   \n",
    "        (\"ordinals4\", OrdinalEncoderNans(ord4_cats), ord4_cat_cols),    \n",
    "    ])\n",
    "\n",
    "data = pipeline_stage1.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28218, 247)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28218, 102)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retrieve the column names\n",
    "\n",
    "This is a bit specific here, but generalizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_column_names(pipeline_transformers):\n",
    "\n",
    "    prepro_columns = []\n",
    "    for line in pipeline_stage1.transformers_[:]:\n",
    "\n",
    "        #print(type(line[1]).__name__ )\n",
    "        if type(line[1]).__name__ == 'OneHotEncoder':\n",
    "            # Note: can include old column identifiers in the OHE feature names\n",
    "            #    with .get_feature_names(ohe_column_names)\n",
    "            new_cols = line[1].get_feature_names().tolist()\n",
    "            #print(line[0],'\\t', len(new_cols))\n",
    "            prepro_columns += new_cols\n",
    "        else:\n",
    "            new_cols = line[2]\n",
    "            #print(line[0],'\\t', len(new_cols))\n",
    "            prepro_columns += new_cols    \n",
    "            \n",
    "    return prepro_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_columns = get_transformed_column_names(pipeline_stage1.transformers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 90 147 7 1\n",
      "248 == 247\n"
     ]
    }
   ],
   "source": [
    "onehot_sum = sum(df[onehot_cat_cols].nunique())\n",
    "check_col_lengths = [len(ignore_cols), len(target_col), len(num_cols), onehot_sum, len(ord2_cat_cols), len(ord4_cat_cols)]\n",
    "print(*check_col_lengths)\n",
    "print(sum(check_col_lengths), '==', len(prepro_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuild the DF and re-cast the data type\n",
    "\n",
    "Prepare for the next pipeline: imputing\n",
    "\n",
    "##### Rebuild the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data, columns=prepro_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Re-cast the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_dtypes = [df_dtype_dict[c] for c in ignore_cols]\n",
    "\n",
    "def set_dtypes(prepro_columns, nonfloat_dtypes):\n",
    "    \"\"\"Set a new dtype dict for the preprocessed df\n",
    "    \n",
    "    Args:\n",
    "      prepro_columns ([str]): columns for the dict keys\n",
    "      nonfloat_dtypes ([str]): datatypes for the non-float datatypes \n",
    "                               (assumes these are in the front of prepro_columns)\n",
    "\n",
    "    Returns:\n",
    "      dict: dictionary of column to datatype\n",
    "    \"\"\"\n",
    "\n",
    "    nr_float_cols = len(prepro_columns)-len(nonfloat_dtypes)\n",
    "\n",
    "    #### NOTE: all preprocess cols will now be floats\n",
    "    dtypes_list = nonfloat_dtypes + (nr_float_cols)*['float']\n",
    "\n",
    "    return dict(zip(prepro_columns, dtypes_list))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_dict = set_dtypes(prepro_columns, ignored_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtypes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(dtypes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>area_m</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>indust_part</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>healthcare_centers_raion</th>\n",
       "      <th>...</th>\n",
       "      <th>x1_Investment</th>\n",
       "      <th>x1_OwnerOccupier</th>\n",
       "      <th>culture_objects_top_25</th>\n",
       "      <th>thermal_power_plant_raion</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>radiation_raion</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>water_1line</th>\n",
       "      <th>ecology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-20</td>\n",
       "      <td>-0.285567</td>\n",
       "      <td>-0.695280</td>\n",
       "      <td>-0.559419</td>\n",
       "      <td>-0.183110</td>\n",
       "      <td>-0.997333</td>\n",
       "      <td>0.112404</td>\n",
       "      <td>-0.325408</td>\n",
       "      <td>-0.191712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>-0.515732</td>\n",
       "      <td>-0.881820</td>\n",
       "      <td>-0.408937</td>\n",
       "      <td>0.854525</td>\n",
       "      <td>-0.578529</td>\n",
       "      <td>0.976425</td>\n",
       "      <td>-0.325408</td>\n",
       "      <td>-0.191712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-08-27</td>\n",
       "      <td>-0.285567</td>\n",
       "      <td>-1.068360</td>\n",
       "      <td>-0.635059</td>\n",
       "      <td>-0.620960</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.688418</td>\n",
       "      <td>-0.325408</td>\n",
       "      <td>-0.191712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>0.890835</td>\n",
       "      <td>0.237419</td>\n",
       "      <td>-0.267325</td>\n",
       "      <td>-0.154878</td>\n",
       "      <td>-0.408564</td>\n",
       "      <td>1.552439</td>\n",
       "      <td>-0.325408</td>\n",
       "      <td>-0.191712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>0.583948</td>\n",
       "      <td>-0.695280</td>\n",
       "      <td>-0.465260</td>\n",
       "      <td>-1.173188</td>\n",
       "      <td>-0.682630</td>\n",
       "      <td>1.264432</td>\n",
       "      <td>-0.325408</td>\n",
       "      <td>1.824339</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  timestamp   full_sq     floor    area_m  green_zone_part  indust_part  \\\n",
       "0   1 2011-08-20 -0.285567 -0.695280 -0.559419        -0.183110    -0.997333   \n",
       "1   2 2011-08-23 -0.515732 -0.881820 -0.408937         0.854525    -0.578529   \n",
       "2   3 2011-08-27 -0.285567 -1.068360 -0.635059        -0.620960     0.003622   \n",
       "3   4 2011-09-01  0.890835  0.237419 -0.267325        -0.154878    -0.408564   \n",
       "4   5 2011-09-05  0.583948 -0.695280 -0.465260        -1.173188    -0.682630   \n",
       "\n",
       "   school_education_centers_raion  school_education_centers_top_20_raion  \\\n",
       "0                        0.112404                              -0.325408   \n",
       "1                        0.976425                              -0.325408   \n",
       "2                        0.688418                              -0.325408   \n",
       "3                        1.552439                              -0.325408   \n",
       "4                        1.264432                              -0.325408   \n",
       "\n",
       "   healthcare_centers_raion  ...  x1_Investment  x1_OwnerOccupier  \\\n",
       "0                 -0.191712  ...            1.0               0.0   \n",
       "1                 -0.191712  ...            1.0               0.0   \n",
       "2                 -0.191712  ...            1.0               0.0   \n",
       "3                 -0.191712  ...            1.0               0.0   \n",
       "4                  1.824339  ...            1.0               0.0   \n",
       "\n",
       "   culture_objects_top_25  thermal_power_plant_raion  incineration_raion  \\\n",
       "0                     0.0                        0.0                 0.0   \n",
       "1                     1.0                        0.0                 0.0   \n",
       "2                     0.0                        0.0                 0.0   \n",
       "3                     0.0                        0.0                 0.0   \n",
       "4                     0.0                        0.0                 0.0   \n",
       "\n",
       "   radiation_raion  big_market_raion  detention_facility_raion  water_1line  \\\n",
       "0              0.0               0.0                       0.0          0.0   \n",
       "1              0.0               0.0                       0.0          0.0   \n",
       "2              1.0               0.0                       0.0          0.0   \n",
       "3              0.0               0.0                       0.0          0.0   \n",
       "4              1.0               0.0                       0.0          0.0   \n",
       "\n",
       "   ecology  \n",
       "0      2.0  \n",
       "1      3.0  \n",
       "2      0.0  \n",
       "3      2.0  \n",
       "4      3.0  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second stage preprocessing\n",
    "\n",
    "### Imputing\n",
    "\n",
    "<font color='green' size=2> \n",
    "    Can this be organized with the above into a single pipeline?\n",
    "    <br/>\n",
    "    Possibly, since the following stage is an imputer\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** `KNNImputer` failed with a kernel restart. Memory? $\\to$ try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprepro_columns = [c for c in prepro_columns if c not in ignore_cols + target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline_stage2 = ColumnTransformer([\n",
    "        (\"ignored\",   FunctionTransformer(lambda x: x), ignore_cols),\n",
    "        ('imputer', SimpleImputer(strategy='median'), subprepro_columns),    \n",
    "    ])\n",
    " \n",
    "####NOTE: still need to Scale the ordinalTransformed feature\n",
    "data = pipeline_stage2.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the DF and re-cast the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOTE: can use the same cols and dtypes as before since no further reordering of columns was made\n",
    "df = pd.DataFrame(data=data, columns=prepro_columns).astype(dtypes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28218 entries, 0 to 28217\n",
      "Data columns (total 247 columns):\n",
      "id                                       28218 non-null int64\n",
      "timestamp                                28218 non-null datetime64[ns]\n",
      "full_sq                                  28218 non-null float64\n",
      "floor                                    28218 non-null float64\n",
      "area_m                                   28218 non-null float64\n",
      "green_zone_part                          28218 non-null float64\n",
      "indust_part                              28218 non-null float64\n",
      "school_education_centers_raion           28218 non-null float64\n",
      "school_education_centers_top_20_raion    28218 non-null float64\n",
      "healthcare_centers_raion                 28218 non-null float64\n",
      "university_top_20_raion                  28218 non-null float64\n",
      "sport_objects_raion                      28218 non-null float64\n",
      "additional_education_raion               28218 non-null float64\n",
      "shopping_centers_raion                   28218 non-null float64\n",
      "male_f                                   28218 non-null float64\n",
      "ekder_male                               28218 non-null float64\n",
      "ID_metro                                 28218 non-null float64\n",
      "metro_min_avto                           28218 non-null float64\n",
      "kindergarten_km                          28218 non-null float64\n",
      "green_zone_km                            28218 non-null float64\n",
      "industrial_km                            28218 non-null float64\n",
      "water_treatment_km                       28218 non-null float64\n",
      "cemetery_km                              28218 non-null float64\n",
      "incineration_km                          28218 non-null float64\n",
      "railroad_station_walk_min                28218 non-null float64\n",
      "ID_railroad_station_walk                 28218 non-null float64\n",
      "railroad_station_avto_min                28218 non-null float64\n",
      "ID_railroad_station_avto                 28218 non-null float64\n",
      "public_transport_station_km              28218 non-null float64\n",
      "water_km                                 28218 non-null float64\n",
      "mkad_km                                  28218 non-null float64\n",
      "big_road1_km                             28218 non-null float64\n",
      "ID_big_road1                             28218 non-null float64\n",
      "big_road2_km                             28218 non-null float64\n",
      "ID_big_road2                             28218 non-null float64\n",
      "railroad_km                              28218 non-null float64\n",
      "zd_vokzaly_avto_km                       28218 non-null float64\n",
      "ID_railroad_terminal                     28218 non-null float64\n",
      "bus_terminal_avto_km                     28218 non-null float64\n",
      "ID_bus_terminal                          28218 non-null float64\n",
      "oil_chemistry_km                         28218 non-null float64\n",
      "nuclear_reactor_km                       28218 non-null float64\n",
      "ts_km                                    28218 non-null float64\n",
      "big_market_km                            28218 non-null float64\n",
      "market_shop_km                           28218 non-null float64\n",
      "fitness_km                               28218 non-null float64\n",
      "swim_pool_km                             28218 non-null float64\n",
      "ice_rink_km                              28218 non-null float64\n",
      "hospice_morgue_km                        28218 non-null float64\n",
      "detention_facility_km                    28218 non-null float64\n",
      "university_km                            28218 non-null float64\n",
      "workplaces_km                            28218 non-null float64\n",
      "office_km                                28218 non-null float64\n",
      "additional_education_km                  28218 non-null float64\n",
      "church_synagogue_km                      28218 non-null float64\n",
      "mosque_km                                28218 non-null float64\n",
      "theater_km                               28218 non-null float64\n",
      "catering_km                              28218 non-null float64\n",
      "green_part_500                           28218 non-null float64\n",
      "prom_part_500                            28218 non-null float64\n",
      "office_count_500                         28218 non-null float64\n",
      "office_sqm_500                           28218 non-null float64\n",
      "trc_count_500                            28218 non-null float64\n",
      "trc_sqm_500                              28218 non-null float64\n",
      "cafe_count_500_price_1000                28218 non-null float64\n",
      "sport_count_500                          28218 non-null float64\n",
      "market_count_500                         28218 non-null float64\n",
      "green_part_1000                          28218 non-null float64\n",
      "trc_sqm_1000                             28218 non-null float64\n",
      "sport_count_1000                         28218 non-null float64\n",
      "market_count_1000                        28218 non-null float64\n",
      "prom_part_1500                           28218 non-null float64\n",
      "trc_sqm_1500                             28218 non-null float64\n",
      "market_count_1500                        28218 non-null float64\n",
      "trc_sqm_2000                             28218 non-null float64\n",
      "cafe_sum_2000_max_price_avg              28218 non-null float64\n",
      "mosque_count_2000                        28218 non-null float64\n",
      "market_count_2000                        28218 non-null float64\n",
      "green_part_3000                          28218 non-null float64\n",
      "prom_part_3000                           28218 non-null float64\n",
      "trc_sqm_3000                             28218 non-null float64\n",
      "cafe_sum_3000_max_price_avg              28218 non-null float64\n",
      "mosque_count_3000                        28218 non-null float64\n",
      "market_count_3000                        28218 non-null float64\n",
      "green_part_5000                          28218 non-null float64\n",
      "prom_part_5000                           28218 non-null float64\n",
      "office_sqm_5000                          28218 non-null float64\n",
      "trc_sqm_5000                             28218 non-null float64\n",
      "cafe_sum_5000_max_price_avg              28218 non-null float64\n",
      "mosque_count_5000                        28218 non-null float64\n",
      "sport_count_5000                         28218 non-null float64\n",
      "market_count_5000                        28218 non-null float64\n",
      "x0_Ajeroport                             28218 non-null float64\n",
      "x0_Akademicheskoe                        28218 non-null float64\n",
      "x0_Alekseevskoe                          28218 non-null float64\n",
      "x0_Altuf'evskoe                          28218 non-null float64\n",
      "x0_Arbat                                 28218 non-null float64\n",
      "x0_Babushkinskoe                         28218 non-null float64\n",
      "x0_Basmannoe                             28218 non-null float64\n",
      "x0_Begovoe                               28218 non-null float64\n",
      "x0_Beskudnikovskoe                       28218 non-null float64\n",
      "x0_Bibirevo                              28218 non-null float64\n",
      "x0_Birjulevo Vostochnoe                  28218 non-null float64\n",
      "x0_Birjulevo Zapadnoe                    28218 non-null float64\n",
      "x0_Bogorodskoe                           28218 non-null float64\n",
      "x0_Brateevo                              28218 non-null float64\n",
      "x0_Butyrskoe                             28218 non-null float64\n",
      "x0_Caricyno                              28218 non-null float64\n",
      "x0_Cheremushki                           28218 non-null float64\n",
      "x0_Chertanovo Central'noe                28218 non-null float64\n",
      "x0_Chertanovo Juzhnoe                    28218 non-null float64\n",
      "x0_Chertanovo Severnoe                   28218 non-null float64\n",
      "x0_Danilovskoe                           28218 non-null float64\n",
      "x0_Dmitrovskoe                           28218 non-null float64\n",
      "x0_Donskoe                               28218 non-null float64\n",
      "x0_Dorogomilovo                          28218 non-null float64\n",
      "x0_Filevskij Park                        28218 non-null float64\n",
      "x0_Fili Davydkovo                        28218 non-null float64\n",
      "x0_Gagarinskoe                           28218 non-null float64\n",
      "x0_Gol'janovo                            28218 non-null float64\n",
      "x0_Golovinskoe                           28218 non-null float64\n",
      "x0_Hamovniki                             28218 non-null float64\n",
      "x0_Horoshevo-Mnevniki                    28218 non-null float64\n",
      "x0_Horoshevskoe                          28218 non-null float64\n",
      "x0_Hovrino                               28218 non-null float64\n",
      "x0_Ivanovskoe                            28218 non-null float64\n",
      "x0_Izmajlovo                             28218 non-null float64\n",
      "x0_Jakimanka                             28218 non-null float64\n",
      "x0_Jaroslavskoe                          28218 non-null float64\n",
      "x0_Jasenevo                              28218 non-null float64\n",
      "x0_Juzhnoe Butovo                        28218 non-null float64\n",
      "x0_Juzhnoe Medvedkovo                    28218 non-null float64\n",
      "x0_Juzhnoe Tushino                       28218 non-null float64\n",
      "x0_Juzhnoportovoe                        28218 non-null float64\n",
      "x0_Kapotnja                              28218 non-null float64\n",
      "x0_Kon'kovo                              28218 non-null float64\n",
      "x0_Koptevo                               28218 non-null float64\n",
      "x0_Kosino-Uhtomskoe                      28218 non-null float64\n",
      "x0_Kotlovka                              28218 non-null float64\n",
      "x0_Krasnosel'skoe                        28218 non-null float64\n",
      "x0_Krjukovo                              28218 non-null float64\n",
      "x0_Krylatskoe                            28218 non-null float64\n",
      "x0_Kuncevo                               28218 non-null float64\n",
      "x0_Kurkino                               28218 non-null float64\n",
      "x0_Kuz'minki                             28218 non-null float64\n",
      "x0_Lefortovo                             28218 non-null float64\n",
      "x0_Levoberezhnoe                         28218 non-null float64\n",
      "x0_Lianozovo                             28218 non-null float64\n",
      "x0_Ljublino                              28218 non-null float64\n",
      "x0_Lomonosovskoe                         28218 non-null float64\n",
      "x0_Losinoostrovskoe                      28218 non-null float64\n",
      "x0_Mar'ina Roshha                        28218 non-null float64\n",
      "x0_Mar'ino                               28218 non-null float64\n",
      "x0_Marfino                               28218 non-null float64\n",
      "x0_Matushkino                            28218 non-null float64\n",
      "x0_Meshhanskoe                           28218 non-null float64\n",
      "x0_Metrogorodok                          28218 non-null float64\n",
      "x0_Mitino                                28218 non-null float64\n",
      "x0_Molzhaninovskoe                       28218 non-null float64\n",
      "x0_Moskvorech'e-Saburovo                 28218 non-null float64\n",
      "x0_Mozhajskoe                            28218 non-null float64\n",
      "x0_Nagatino-Sadovniki                    28218 non-null float64\n",
      "x0_Nagatinskij Zaton                     28218 non-null float64\n",
      "x0_Nagornoe                              28218 non-null float64\n",
      "x0_Nekrasovka                            28218 non-null float64\n",
      "x0_Nizhegorodskoe                        28218 non-null float64\n",
      "x0_Novo-Peredelkino                      28218 non-null float64\n",
      "x0_Novogireevo                           28218 non-null float64\n",
      "x0_Novokosino                            28218 non-null float64\n",
      "x0_Obruchevskoe                          28218 non-null float64\n",
      "x0_Ochakovo-Matveevskoe                  28218 non-null float64\n",
      "x0_Orehovo-Borisovo Juzhnoe              28218 non-null float64\n",
      "x0_Orehovo-Borisovo Severnoe             28218 non-null float64\n",
      "x0_Ostankinskoe                          28218 non-null float64\n",
      "x0_Otradnoe                              28218 non-null float64\n",
      "x0_Pechatniki                            28218 non-null float64\n",
      "x0_Perovo                                28218 non-null float64\n",
      "x0_Pokrovskoe Streshnevo                 28218 non-null float64\n",
      "x0_Poselenie Desjonovskoe                28218 non-null float64\n",
      "x0_Poselenie Filimonkovskoe              28218 non-null float64\n",
      "x0_Poselenie Kievskij                    28218 non-null float64\n",
      "x0_Poselenie Kokoshkino                  28218 non-null float64\n",
      "x0_Poselenie Krasnopahorskoe             28218 non-null float64\n",
      "x0_Poselenie Marushkinskoe               28218 non-null float64\n",
      "x0_Poselenie Mihajlovo-Jarcevskoe        28218 non-null float64\n",
      "x0_Poselenie Moskovskij                  28218 non-null float64\n",
      "x0_Poselenie Mosrentgen                  28218 non-null float64\n",
      "x0_Poselenie Novofedorovskoe             28218 non-null float64\n",
      "x0_Poselenie Pervomajskoe                28218 non-null float64\n",
      "x0_Poselenie Rjazanovskoe                28218 non-null float64\n",
      "x0_Poselenie Rogovskoe                   28218 non-null float64\n",
      "x0_Poselenie Shhapovskoe                 28218 non-null float64\n",
      "x0_Poselenie Shherbinka                  28218 non-null float64\n",
      "x0_Poselenie Sosenskoe                   28218 non-null float64\n",
      "x0_Poselenie Vnukovskoe                  28218 non-null float64\n",
      "x0_Poselenie Voronovskoe                 28218 non-null float64\n",
      "x0_Poselenie Voskresenskoe               28218 non-null float64\n",
      "x0_Preobrazhenskoe                       28218 non-null float64\n",
      "x0_Presnenskoe                           28218 non-null float64\n",
      "x0_Prospekt Vernadskogo                  28218 non-null float64\n",
      "x0_Ramenki                               28218 non-null float64\n",
      "x0_Rjazanskij                            28218 non-null float64\n",
      "x0_Rostokino                             28218 non-null float64\n",
      "x0_Savelki                               28218 non-null float64\n",
      "x0_Savelovskoe                           28218 non-null float64\n",
      "x0_Severnoe                              28218 non-null float64\n",
      "x0_Severnoe Butovo                       28218 non-null float64\n",
      "x0_Severnoe Izmajlovo                    28218 non-null float64\n",
      "x0_Severnoe Medvedkovo                   28218 non-null float64\n",
      "x0_Severnoe Tushino                      28218 non-null float64\n",
      "x0_Shhukino                              28218 non-null float64\n",
      "x0_Silino                                28218 non-null float64\n",
      "x0_Sokol                                 28218 non-null float64\n",
      "x0_Sokol'niki                            28218 non-null float64\n",
      "x0_Sokolinaja Gora                       28218 non-null float64\n",
      "x0_Solncevo                              28218 non-null float64\n",
      "x0_Staroe Krjukovo                       28218 non-null float64\n",
      "x0_Strogino                              28218 non-null float64\n",
      "x0_Sviblovo                              28218 non-null float64\n",
      "x0_Taganskoe                             28218 non-null float64\n",
      "x0_Tekstil'shhiki                        28218 non-null float64\n",
      "x0_Teplyj Stan                           28218 non-null float64\n",
      "x0_Timirjazevskoe                        28218 non-null float64\n",
      "x0_Troickij okrug                        28218 non-null float64\n",
      "x0_Troparevo-Nikulino                    28218 non-null float64\n",
      "x0_Tverskoe                              28218 non-null float64\n",
      "x0_Veshnjaki                             28218 non-null float64\n",
      "x0_Vnukovo                               28218 non-null float64\n",
      "x0_Vojkovskoe                            28218 non-null float64\n",
      "x0_Vostochnoe                            28218 non-null float64\n",
      "x0_Vostochnoe Degunino                   28218 non-null float64\n",
      "x0_Vostochnoe Izmajlovo                  28218 non-null float64\n",
      "x0_Vyhino-Zhulebino                      28218 non-null float64\n",
      "x0_Zamoskvorech'e                        28218 non-null float64\n",
      "x0_Zapadnoe Degunino                     28218 non-null float64\n",
      "x0_Zjablikovo                            28218 non-null float64\n",
      "x0_Zjuzino                               28218 non-null float64\n",
      "x1_Investment                            28218 non-null float64\n",
      "x1_OwnerOccupier                         28218 non-null float64\n",
      "culture_objects_top_25                   28218 non-null float64\n",
      "thermal_power_plant_raion                28218 non-null float64\n",
      "incineration_raion                       28218 non-null float64\n",
      "radiation_raion                          28218 non-null float64\n",
      "big_market_raion                         28218 non-null float64\n",
      "detention_facility_raion                 28218 non-null float64\n",
      "water_1line                              28218 non-null float64\n",
      "ecology                                  28218 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(245), int64(1)\n",
      "memory usage: 53.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last transform to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "stasca = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targ['price_doc_'] = stasca.fit_transform(df_targ['price_doc'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "      <th>price_doc_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5850000</td>\n",
       "      <td>-0.306309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6000000</td>\n",
       "      <td>-0.274351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5700000</td>\n",
       "      <td>-0.338267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13100000</td>\n",
       "      <td>1.238313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16331452</td>\n",
       "      <td>1.926777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  price_doc  price_doc_\n",
       "0   1    5850000   -0.306309\n",
       "1   2    6000000   -0.274351\n",
       "2   3    5700000   -0.338267\n",
       "3   4   13100000    1.238313\n",
       "4   5   16331452    1.926777"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28218, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "      <th>price_doc_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5850000</td>\n",
       "      <td>-0.306309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6000000</td>\n",
       "      <td>-0.274351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5700000</td>\n",
       "      <td>-0.338267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13100000</td>\n",
       "      <td>1.238313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16331452</td>\n",
       "      <td>1.926777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  price_doc  price_doc_\n",
       "0   1    5850000   -0.306309\n",
       "1   2    6000000   -0.274351\n",
       "2   3    5700000   -0.338267\n",
       "3   4   13100000    1.238313\n",
       "4   5   16331452    1.926777"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28218, 247), (28218, 3))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_targ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.merge(df_targ, on=['id'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: solid rgb(0,0,0) 0.0px; background-color: rgb(0,0,0);height: 4.0px;\"/>\n",
    "\n",
    "# Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_out.to_csv('../../datasets/sberbank-russian-housing-market/train_prepro.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 sandm sandm 66M Mai 28 14:10 ../../datasets/sberbank-russian-housing-market/train_prepro.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -h -lat ../../datasets/sberbank-russian-housing-market/train_prepro.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
