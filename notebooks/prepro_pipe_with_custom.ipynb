{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "    Sberbank Russian Housing Market\n",
    "</font>\n",
    "\n",
    "<hr style=\"border: solid rgb(255,0,0) 0.0px; background-color: rgb(255,0,0);height: 2.0px;\"/>\n",
    "<font color='red' size=5>\n",
    "    Summary: part of feature selection study (v. 0)\n",
    "</font>\n",
    "<hr style=\"border: solid rgb(255,0,0) 0.0px; background-color: rgb(255,0,0);height: 2.0px;\"/>\n",
    "\n",
    "Feature importance using the build-ins from a few different classifiers:\n",
    "* RandomForestRegressor    \n",
    "* GradientBoostingRegressor\n",
    "* AdaBoostRegressor\n",
    "* LGBMRegressor\n",
    "* XGBRegressor\n",
    "\n",
    "There are more methods from sklearn; see [feature-selection](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, 20)]\n",
    "random.shuffle(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.append('./helpers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset_selective sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/sberbank-russian-housing-market/train.csv', \\\n",
    "                 infer_datetime_format=True, parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes('float').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = df.select_dtypes('int').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = df.select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical encoding\n",
    "\n",
    "### Homebrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'categorical_encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-105df7225eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcategorical_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcategorical_encoding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cat_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'categorical_encoding'"
     ]
    }
   ],
   "source": [
    "import categorical_encoding\n",
    "importlib.reload(categorical_encoding)\n",
    "from categorical_encoding import get_cat_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string_cols = df[['id'] + string_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string_cols = get_cat_encoding(df_string_cols, string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=yes_no_cols).merge(df_string_cols, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy**\n",
    "\n",
    "Create pipelines for the categorical and numerical features \n",
    "\n",
    "1. using `ColumnTransformer`, `FunctionTransformer` and `Pipeline`\n",
    "    * allows individual feature selections\n",
    "\n",
    "```\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or \n",
    "\n",
    "2. using `Pipelines`\n",
    "    * selection is done inside custom methods\n",
    "    \n",
    "    ```\n",
    "        #Categrical features to pass down the categorical pipeline \n",
    "        cat_features = ['date', 'waterfront', 'view', 'yr_renovated']\n",
    "\n",
    "        #Numerical features to pass down the numerical pipeline \n",
    "        num_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "                        'condition', 'grade', 'sqft_basement', 'yr_built']\n",
    "\n",
    "        #Defining the steps in the categorical pipeline \n",
    "        cat_pipeline = Pipeline( \n",
    "                                steps = [ ( 'cat_selector', FeatureSelector(cat_features) ),\n",
    "                                          ( 'cat_transformer', CategoricalTransformer() ), \n",
    "                                          ( 'one_hot_encoder', OneHotEncoder( sparse = False ) ) ] )\n",
    "\n",
    "        #Defining the steps in the numerical pipeline     \n",
    "        num_pipeline = Pipeline( \n",
    "                                steps = [ ( 'num_selector', FeatureSelector(num_features) ),\n",
    "                                          ( 'num_transformer', NumericalTransformer() ),\n",
    "                                          ('imputer', SimpleImputer(strategy = 'median') ),\n",
    "                                          ( 'std_scaler', StandardScaler() ) \n",
    "                                          ] )\n",
    "\n",
    "        #Combining numerical and categorical piepline into one full big pipeline horizontally \n",
    "        #using FeatureUnion\n",
    "        full_pipeline = FeatureUnion( transformer_list = [ ( 'cat_pipeline', cat_pipeline ), \n",
    "\n",
    "                                                          ( 'num_pipeline', num_pipeline ) ] )        \n",
    "    ```\n",
    "    \n",
    "    * **note**  _all_ features returned by `FeatureSelector` are passed into the transformers since pipelines can only deal with the whole array passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product_type', 'sub_area', 'culture_objects_top_25', 'thermal_power_plant_raion', 'incineration_raion', 'oil_chemistry_raion', 'radiation_raion', 'railroad_terminal_raion', 'big_market_raion', 'nuclear_reactor_raion', 'detention_facility_raion', 'water_1line', 'big_road1_1line', 'railroad_1line', 'ecology']\n"
     ]
    }
   ],
   "source": [
    "print(string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>culture_objects_top_25</th>\n",
       "      <th>thermal_power_plant_raion</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>oil_chemistry_raion</th>\n",
       "      <th>radiation_raion</th>\n",
       "      <th>railroad_terminal_raion</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>nuclear_reactor_raion</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>water_1line</th>\n",
       "      <th>big_road1_1line</th>\n",
       "      <th>railroad_1line</th>\n",
       "      <th>ecology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Bibirevo</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Nagatinskij Zaton</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Tekstil'shhiki</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Mitino</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investment</td>\n",
       "      <td>Basmannoe</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type           sub_area culture_objects_top_25  \\\n",
       "0   Investment           Bibirevo                     no   \n",
       "1   Investment  Nagatinskij Zaton                    yes   \n",
       "2   Investment     Tekstil'shhiki                     no   \n",
       "3   Investment             Mitino                     no   \n",
       "4   Investment          Basmannoe                     no   \n",
       "\n",
       "  thermal_power_plant_raion incineration_raion oil_chemistry_raion  \\\n",
       "0                        no                 no                  no   \n",
       "1                        no                 no                  no   \n",
       "2                        no                 no                  no   \n",
       "3                        no                 no                  no   \n",
       "4                        no                 no                  no   \n",
       "\n",
       "  radiation_raion railroad_terminal_raion big_market_raion  \\\n",
       "0              no                      no               no   \n",
       "1              no                      no               no   \n",
       "2             yes                      no               no   \n",
       "3              no                      no               no   \n",
       "4             yes                     yes               no   \n",
       "\n",
       "  nuclear_reactor_raion detention_facility_raion water_1line big_road1_1line  \\\n",
       "0                    no                       no          no              no   \n",
       "1                    no                       no          no              no   \n",
       "2                    no                       no          no              no   \n",
       "3                    no                       no          no              no   \n",
       "4                    no                       no          no              no   \n",
       "\n",
       "  railroad_1line    ecology  \n",
       "0             no       good  \n",
       "1             no  excellent  \n",
       "2             no       poor  \n",
       "3             no       good  \n",
       "4            yes  excellent  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[string_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "* Ordinals:\n",
    "    * 'ecology'\n",
    "* OneHots\n",
    "    * 'sub_area', 'product_type' (but only two vals)\n",
    "* Binaries\n",
    "    * the rest\n",
    "    * _But these will also be considered ordinals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>satisfactory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ecology\n",
       "0          good\n",
       "1     excellent\n",
       "2          poor\n",
       "3          good\n",
       "4     excellent\n",
       "5          poor\n",
       "6          poor\n",
       "7          good\n",
       "8          poor\n",
       "9  satisfactory"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df_ecology = df[[\"ecology\"]]\n",
    "df_ecology.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_list = [['Investment', 'OwnerOccupier']] + [df.sub_area.unique().tolist()] + 12*[['no','yes']]+[['poor', 'satisfactory', 'good', 'excellent', 'no data']]\n",
    "\n",
    "enc = OrdinalEncoder(categ_list)\n",
    "\n",
    "str_enc_data = enc.fit_transform(df[cols_to_encode].values)\n",
    "\n",
    "# 5. rewrite encoded to the data\n",
    "df[cols_to_encode] = str_enc_data\n",
    "\n",
    "\n",
    "# **Note** refill any NANs wished to be retained\n",
    "#TODO move to separate function\n",
    "encoder_max = df.ecology.max()\n",
    "df['ecology'] = np.where(df.ecology==df.ecology.max(), np.NaN, df.ecology)\n",
    "\n",
    "# 6. Recast the data, if needed\n",
    "\n",
    "df[cols_to_encode[:-1]] = df[cols_to_encode[:-1]].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord4_cats = [['poor', 'satisfactory', 'good', 'excellent', 'no data']]\n",
    "ord4_enc = OrdinalEncoder(ord4_cats)\n",
    "df_ecology = df[[\"ecology\"]]\n",
    "df_ecology = ord4_enc.fit_transform(df[[\"ecology\"]])\n",
    "df_ecology[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_cat_cols = [\"sub_area\", \"product_type\"]\n",
    "\n",
    "# By default, the OneHotEncoder class returns a sparse array, but we can convert it to a dense array if needed by calling the toarray() method:\n",
    "# Alternatively, you can set sparse=False when creating the OneHotEncoder:\n",
    "onehots = OneHotEncoder(sparse=False)\n",
    "housing_cat_1hot = onehots.fit_transform(df[onehot_cat_cols])\n",
    "housing_cat_1hot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    excellent\n",
       "1    excellent\n",
       "2         poor\n",
       "3         poor\n",
       "4         good\n",
       "Name: ecology, dtype: object"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df['ecology'].sample(100, ).reset_index(drop=True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_encoder(mapping):\n",
    "    \n",
    "    map_func = lambda x: mapping[x]\n",
    "    \n",
    "    def inner(data):\n",
    "        \n",
    "        output = np.array(list(map(map_func, data)))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    return inner\n",
    "        \n",
    "\n",
    "ecology_map = dict(zip(['good', 'excellent', 'poor', 'satisfactory', 'no data'],[2,3,0,1,4]))\n",
    "\n",
    "ecology_nanmap = dict(zip(range(5),list(range(4))+[np.nan]))\n",
    "\n",
    "encoder = lambda x: mapping_encoder(ecology_nanmap)( mapping_encoder(ecology_map)(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent' 'poor' 'good' 'no data' 'satisfactory']\n",
      "[ 3.  0.  2. nan  1.]\n",
      "[ 3.  0.  2. nan  1.]\n",
      "[ True  True  True False  True]\n"
     ]
    }
   ],
   "source": [
    "test_arr = np.array(['excellent', 'poor',  'good', 'no data', 'satisfactory'], dtype=object)\n",
    "result_arr = np.array([ 3.,  0.,  2.,   np.nan,  1.], dtype=np.float64)\n",
    "\n",
    "if not all(result_arr == encoder(test_arr)):\n",
    "    # np.Nans aren't equivalent?\n",
    "    print(test_arr)\n",
    "    print(result_arr)    \n",
    "    print(encoder(test_arr))\n",
    "    print(result_arr == encoder(test_arr))\n",
    "else:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  0., ..., nan,  1.,  0.])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit_transform(df['ecology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalEncoderNans(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    #Class Constructor\n",
    "    def __init__( self, _cats_to_map):\n",
    "        self._cats_to_map = _cats_to_map\n",
    "        \n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \n",
    "    def transform(self, X, y = None):\n",
    "            \n",
    "        # Map all but the last the categories to ints\n",
    "        X = X.replace( self._cats_to_map[:-1], np.arange(len(self._cats_to_map[:-1])))\n",
    "                    \n",
    "        #Converting any infinity values in the dataset to Nan\n",
    "        X = X.replace( self._cats_to_map[-1], np.nan )\n",
    "        \n",
    "        shape_ = X.shape[0]\n",
    "        #returns a numpy array\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord4_enc_nan = OrdinalEncoderNans(ord4_cats)\n",
    "housing_extra_attribs = ord4_enc_nan.fit_transform(df[ord4_cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30471, (30471, 1), array([[ 2.],\n",
       "        [ 3.],\n",
       "        [ 0.],\n",
       "        ...,\n",
       "        [nan],\n",
       "        [ 1.],\n",
       "        [ 0.]]))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_shape = housing_extra_attribs.shape[0]\n",
    "housing_extra_attribs.reshape(test_shape,)\n",
    "test_shape, housing_extra_attribs.shape, housing_extra_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "df_num_tr = num_pipeline.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### putting the cat-encs together into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(encoder)\n",
    "\n",
    "onehot_cat_cols = [\"sub_area\", \"product_type\"]\n",
    "\n",
    "ord4_cat_cols = [\"ecology\"]\n",
    "ord4_cats = ['poor', 'satisfactory', 'good', 'excellent', 'no data']\n",
    "\n",
    "ord2_cat_cols = [e for e in string_cols if (e not in onehot_cat_cols) & (e not in ord4_cat_cols) ]\n",
    "ord2_cats = 12*[[\"no\", \"yes\"]]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num_pipe\", num_pipeline, num_cols),\n",
    "        (\"onehots\", OneHotEncoder(sparse=False), onehot_cat_cols),\n",
    "        (\"ordinals2\", OrdinalEncoder(ord2_cats), ord2_cat_cols),   \n",
    "        (\"ordinals4\", OrdinalEncoderNans(ord4_cats), ord4_cat_cols),    \n",
    "    ])\n",
    "\n",
    "df_cat_prepared = full_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30471, 437)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From external source example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "#Custom Transformer that extracts columns passed as argument to its constructor \n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ] \n",
    "\n",
    "#Custom transformer that breaks dates column into year, month and day into separate columns and\n",
    "#converts certain features to binary \n",
    "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
    "    #Class constructor method that takes in a list of values as its argument\n",
    "    def __init__(self, use_dates = ['year', 'month', 'day'] ):\n",
    "        self._use_dates = use_dates\n",
    "        \n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "\n",
    "    #Helper function to extract year from column 'dates' \n",
    "    def get_year( self, obj ):\n",
    "        return str(obj)[:4]\n",
    "    \n",
    "    #Helper function to extract month from column 'dates'\n",
    "    def get_month( self, obj ):\n",
    "        return str(obj)[4:6]\n",
    "    \n",
    "    #Helper function to extract day from column 'dates'\n",
    "    def get_day(self, obj):\n",
    "        return str(obj)[6:8]\n",
    "    \n",
    "    #Helper function that converts values to Binary depending on input \n",
    "    def create_binary(self, obj):\n",
    "        if obj == 0:\n",
    "            return 'No'\n",
    "        else:\n",
    "            return 'Yes'\n",
    "    \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):\n",
    "        #Depending on constructor argument break dates column into specified units\n",
    "        #using the helper functions written above \n",
    "        for spec in self._use_dates:\n",
    "\n",
    "        exec( \"X.loc[:,'{}'] = X['date'].apply(self.get_{})\".format( spec, spec ) )\n",
    "        #Drop unusable column \n",
    "        X = X.drop('date', axis = 1 )\n",
    "\n",
    "        #Convert these columns to binary for one-hot-encoding later\n",
    "        X.loc[:,'waterfront'] = X['waterfront'].apply( self.create_binary )\n",
    "\n",
    "        X.loc[:,'view'] = X['view'].apply( self.create_binary )\n",
    "\n",
    "        X.loc[:,'yr_renovated'] = X['yr_renovated'].apply( self.create_binary )\n",
    "        #returns numpy array\n",
    "        return X.values \n",
    "\n",
    "#Custom transformer we wrote to engineer features ( bathrooms per bedroom and/or how old the house is in 2019  ) \n",
    "#passed as boolen arguements to its constructor\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor\n",
    "    def __init__( self, bath_per_bed = True, years_old = True ):\n",
    "        self._bath_per_bed = bath_per_bed\n",
    "        self._years_old = years_old\n",
    "        \n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \n",
    "    def transform(self, X, y = None):\n",
    "        #Check if needed \n",
    "        if self._bath_per_bed:\n",
    "            #create new column\n",
    "            X.loc[:,'bath_per_bed'] = X['bathrooms'] / X['bedrooms']\n",
    "            #drop redundant column\n",
    "            X.drop('bathrooms', axis = 1 )\n",
    "        #Check if needed     \n",
    "        if self._years_old:\n",
    "            #create new column\n",
    "            X.loc[:,'years_old'] =  2019 - X['yr_built']\n",
    "            #drop redundant column \n",
    "            X.drop('yr_built', axis = 1)\n",
    "            \n",
    "        #Converting any infinity values in the dataset to Nan\n",
    "        X = X.replace( [ np.inf, -np.inf ], np.nan )\n",
    "        #returns a numpy array\n",
    "        return X.values\n",
    "\n",
    "#Categrical features to pass down the categorical pipeline \n",
    "cateforical_features = ['date', 'waterfront', 'view', 'yr_renovated']\n",
    "\n",
    "#Numerical features to pass down the numerical pipeline \n",
    "numerical_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "                'condition', 'grade', 'sqft_basement', 'yr_built']\n",
    "\n",
    "#Defining the steps in the categorical pipeline \n",
    "categorical_pipeline = Pipeline( steps = [ ( 'cat_selector', FeatureSelector(categorical_features) ),\n",
    "                                  \n",
    "                                  ( 'cat_transformer', CategoricalTransformer() ), \n",
    "                                  \n",
    "                                  ( 'one_hot_encoder', OneHotEncoder( sparse = False ) ) ] )\n",
    "    \n",
    "#Defining the steps in the numerical pipeline     \n",
    "numerical_pipeline = Pipeline( steps = [ ( 'num_selector', FeatureSelector(numerical_features) ),\n",
    "                                  \n",
    "                                  ( 'num_transformer', NumericalTransformer() ),\n",
    "                                  \n",
    "                                  ('imputer', SimpleImputer(strategy = 'median') ),\n",
    "                                  \n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "#Combining numerical and categorical piepline into one full big pipeline horizontally \n",
    "#using FeatureUnion\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'categorical_pipeline', categorical_pipeline ), \n",
    "                                                  \n",
    "                                                  ( 'numerical_pipeline', numerical_pipeline ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_encoding(df, cols_to_encode):\n",
    "    \n",
    "    # 1. Copy the data\n",
    "    # 2. ~~data inspection~~\n",
    "    #    * deep-dive into some cols\n",
    "    # 3. ~~select the cols to be transformed~~ --> given\n",
    "    # 4. Get the encoder; specify the data to encode and transform\n",
    "    # **Note** this list is specific to this data but it could be passed as argument\n",
    "    #TODO move to separate function\n",
    "    categ_list = [['Investment', 'OwnerOccupier']] + [df.sub_area.unique().tolist()] + 12*[['no','yes']]+[['poor', 'satisfactory', 'good', 'excellent', 'no data']]\n",
    "    \n",
    "    enc = OrdinalEncoder(categ_list)\n",
    "\n",
    "    str_enc_data = enc.fit_transform(df[cols_to_encode].values)\n",
    "\n",
    "    # 5. rewrite encoded to the data\n",
    "    df[cols_to_encode] = str_enc_data\n",
    "\n",
    "\n",
    "    # **Note** refill any NANs wished to be retained\n",
    "    #TODO move to separate function\n",
    "    encoder_max = df.ecology.max()\n",
    "    df['ecology'] = np.where(df.ecology==df.ecology.max(), np.NaN, df.ecology)\n",
    "\n",
    "    # 6. Recast the data, if needed\n",
    "\n",
    "    df[cols_to_encode[:-1]] = df[cols_to_encode[:-1]].astype('int8')\n",
    "\n",
    "    # 7. Final check on the data: does it contain all the rows as before?\n",
    "    # 8. Replace the encoded data (excluded here)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
